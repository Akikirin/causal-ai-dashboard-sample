import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import graphviz
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.model_selection import KFold
import warnings
from scipy.stats import norm

# --- 1. Machine Learning & Causal Imports ---
try:
    from xgboost import XGBRegressor
except ImportError:
    st.error("ğŸš¨ Please install xgboost: `pip install xgboost` / è«‹å®‰è£ xgboost")
    st.stop()

try:
    from econml.dml import LinearDML
except ImportError:
    st.error("ğŸš¨ Critical Missing Library: Please run `pip install econml` / ç¼ºå¤±å¿…è¦å¥—ä»¶ï¼šè«‹åŸ·è¡Œ pip install econml")
    st.stop()

try:
    from causalml.inference.meta import BaseSRegressor, BaseTRegressor, BaseXRegressor
except ImportError:
    st.error("ğŸš¨ Critical Missing Library: Please run `pip install causalml` / ç¼ºå¤±å¿…è¦å¥—ä»¶ï¼šè«‹åŸ·è¡Œ pip install causalml")
    st.stop()

from fpdf import FPDF

# Suppress warnings
warnings.filterwarnings('ignore')

# ==========================================
# 2. Page Configuration & Professional CSS
# ==========================================
st.set_page_config(layout="wide", page_title="Universal Causal Dashboard", page_icon="ğŸ”®")

# Translation Helper Function
def t(en, tw):
    return f"{en} | {tw}"

st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Josefin+Sans&display=swap');
    html, body, [class*="css"], font, div, span, p, text {
        font-family: 'Josefin Sans', sans-serif !important;
    }
    h1, h2, h3, h4, h5, h6 {
        color: #0f172a !important;
        font-family: 'Josefin Sans', sans-serif !important;
        font-weight: 800 !important;
        letter-spacing: -0.5px;
    }
    [data-testid="stMetricValue"] { color: #000000 !important; font-family: 'Josefin Sans', sans-serif !important; }
    .stTabs [data-baseweb="tab"] { font-family: 'Josefin Sans', sans-serif !important; font-size: 1.1rem; font-weight: 600; }
    .theory-box {
        background-color: #f0f9ff;
        border-left: 5px solid #0ea5e9;
        padding: 15px;
        margin-bottom: 20px;
        border-radius: 4px;
        font-size: 0.95rem;
        color: #334155;
    }
    .comp-delta-pos { color: #059669; font-weight: bold; }
    .comp-delta-neg { color: #dc2626; font-weight: bold; }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 3. Data Processing & Logic
# ==========================================
@st.cache_data
def load_data(file):
    return pd.read_csv(file)

def auto_feature_eng(df, target, treatment):
    df = df.copy()
    lag_cols = []
    for i in [1, 2, 3]:
        col_name = f'{target}_Lag{i}'
        df[col_name] = df[target].shift(i)
        lag_cols.append(col_name)
    df = df.dropna().reset_index(drop=True)
    scaler = StandardScaler()
    if lag_cols:
        pca = PCA(n_components=1)
        df['Latent_Market_State'] = pca.fit_transform(scaler.fit_transform(df[lag_cols]))
    else:
        df['Latent_Market_State'] = 0
    return df

def simulate_inventory_dynamic(demand_series, target_series, lead_time):
    inv_levels = []
    current_stock = target_series[0]
    shortage_events = 0
    lost_sales = []
    
    for day in range(len(demand_series)):
        demand = demand_series[day]
        if current_stock >= demand:
            current_stock -= demand
            lost_sales.append(0)
        else:
            lost = demand - current_stock
            lost_sales.append(lost)
            current_stock = 0
            shortage_events += 1
        inv_levels.append(current_stock)
        if (day + 1) % lead_time == 0:
            next_target = target_series[min(day+1, len(target_series)-1)]
            current_stock = next_target
    return np.array(inv_levels), shortage_events, np.array(lost_sales)

# ==========================================
# 4. Engine Classes
# ==========================================
class RealCausalEngine:
    def __init__(self):
        self.dml_est = LinearDML(
            model_y=RandomForestRegressor(n_estimators=50, min_samples_leaf=5),
            model_t=RandomForestRegressor(n_estimators=50, min_samples_leaf=5),
            random_state=42,
            cv=3
        )
        self.base_model = XGBRegressor(n_estimators=100, random_state=42)
        self.features = []
        self.treatment = ""
        self.confounders = []

    def train(self, df, target_col, treatment_col, confounders, heterogeneity_cols=None):
        self.target = target_col
        self.treatment = treatment_col
        self.confounders = confounders
        X = df[heterogeneity_cols] if heterogeneity_cols else None
        W = df[confounders]
        Y = df[target_col]
        T = df[treatment_col]

        with st.spinner(t("ğŸ§  Engines warming up... DML running 3-Fold Cross-Fitting...", "ğŸ§  å¼•æ“å•Ÿå‹•ä¸­... æ­£åœ¨é€²è¡Œ DML ä¸‰æŠ˜äº¤å‰é©—è­‰...")):
            self.dml_est.fit(Y, T, X=X, W=W)
            all_feats = [treatment_col] + confounders + (heterogeneity_cols if heterogeneity_cols else [])
            self.base_model.fit(df[all_feats], Y)
            self.features = all_feats

    def get_causal_effect(self, X_pred):
        return self.dml_est.effect(X_pred)

    def predict_counterfactual(self, df_input, new_price_col):
        base_pred = self.base_model.predict(df_input[self.features])
        delta_t = df_input[new_price_col] - df_input[self.treatment]
        if 'Latent_Market_State' in df_input.columns:
            theta = self.dml_est.effect(df_input[['Latent_Market_State']])
        else:
            theta = self.dml_est.const_marginal_effect(df_input[self.confounders])
        counterfactual_sales = base_pred + (theta * delta_t)
        return np.maximum(counterfactual_sales, 0)

def train_meta_learners(df, target_col, treatment_col, feature_cols):
    X = df[feature_cols]
    y = df[target_col]
    w = df[treatment_col].copy()
    if w.nunique() > 2:
        median_val = w.median()
        w_binary = (w > median_val).astype(int)
    else:
        w_binary = w.astype(int)

    results = {}
    learner_s = BaseSRegressor(learner=LinearRegression())
    cate_s = learner_s.fit_predict(X=X, treatment=w_binary, y=y)
    results['S-Learner'] = cate_s.flatten()

    learner_t = BaseTRegressor(learner=XGBRegressor(n_estimators=50, verbosity=0))
    cate_t = learner_t.fit_predict(X=X, treatment=w_binary, y=y)
    results['T-Learner'] = cate_t.flatten()
    
    learner_x = BaseXRegressor(learner=XGBRegressor(n_estimators=50, verbosity=0))
    cate_x = learner_x.fit_predict(X=X, treatment=w_binary, y=y)
    results['X-Learner'] = cate_x.flatten()
    return pd.DataFrame(results)

# ==========================================
# 5. Main Application Logic
# ==========================================
col_title, col_logo = st.columns([5, 1])
with col_title:
    st.title(t("ğŸ§  Causal AI Strategy Dashboard", "ğŸ§  å› æœ AI ç­–ç•¥å„€è¡¨æ¿"))
    st.markdown(t("Quantify the **True Impact** of your decisions using Double Machine Learning.", "åˆ©ç”¨ **é›™é‡æ©Ÿå™¨å­¸ç¿’ (DML)** é‡åŒ–æ±ºç­–çš„ **çœŸå¯¦å½±éŸ¿åŠ›**ã€‚"))

with st.sidebar:
    st.header(t("ğŸ›ï¸ Control Tower", "ğŸ›ï¸ æ§åˆ¶å°"))
    st.info(t("Upload your historical sales data to begin causal inference.", "ä¸Šå‚³æ­·å²éŠ·å”®æ•¸æ“šä»¥é–‹å§‹å› æœæ¨æ–·ã€‚"))
    uploaded_file = st.file_uploader(t("Upload CSV Data", "ä¸Šå‚³ CSV æ•¸æ“š"), type="csv")
    
    if uploaded_file:
        raw_df = load_data(uploaded_file)
        cols = raw_df.select_dtypes(include=np.number).columns.tolist()
        st.markdown(t("### 1. Model Configuration", "### 1. æ¨¡å‹é…ç½®"))
        target_col = st.selectbox(t("ğŸ¯ Target (Outcome Y)", "ğŸ¯ ç›®æ¨™è®Šæ•¸ (çµæœ Y)"), cols, index=0)
        treatment_col = st.selectbox(t("ğŸ’Š Treatment (Input T)", "ğŸ’Š å¹²é è®Šæ•¸ (è¼¸å…¥ T)"), cols, index=1)
        avail_cols = [c for c in cols if c not in [target_col, treatment_col]]
        confounders = st.multiselect(t("ğŸŒªï¸ Confounders (Controls W)", "ğŸŒªï¸ æ··é›œå› å­ (æ§åˆ¶è®Šæ•¸ W)"), avail_cols, default=avail_cols[:2])
        
        st.markdown(t("### 2. Execution", "### 2. åŸ·è¡Œ"))
        if st.button(t("ğŸš€ Run Causal Engine", "ğŸš€ å•Ÿå‹•å› æœå¼•æ“"), type="primary", use_container_width=True):
            st.session_state['run'] = True
            st.session_state['cate_results'] = None
            st.session_state['fold_metrics'] = None
            st.session_state['ols_fold_metrics'] = None
            st.session_state['sim_results'] = None
    else:
        st.caption(t("Waiting for data...", "ç­‰å¾…æ•¸æ“šä¸Šå‚³..."))

# --- Main Content ---
if st.session_state.get('run', False) and uploaded_file:
    df_eng = auto_feature_eng(raw_df, target_col, treatment_col)
    train_size = int(len(df_eng) * 0.8)
    train_df = df_eng.iloc[:train_size]
    test_df = df_eng.iloc[train_size:].reset_index(drop=True)
    all_confounders = confounders + [c for c in df_eng.columns if 'Lag' in c]

    st.markdown("---")
    m_col1, m_col2, m_col3, m_col4 = st.columns(4)
    m_col1.metric(t("Observation Window", "è§€å¯Ÿçª—å£"), f"{len(df_eng)} " + t("Periods", "é€±æœŸ"))
    m_col2.metric(t("Target Variable", "ç›®æ¨™è®Šæ•¸"), target_col)
    m_col3.metric(t("Treatment Variable", "å¹²é è®Šæ•¸"), treatment_col)
    m_col4.metric(t("Confounders Tracked", "è¿½è¹¤æ··é›œå› å­æ•¸"), len(all_confounders))
    st.markdown("---")

    if 'main_engine' not in st.session_state:
        engine = RealCausalEngine()
        engine.train(train_df, target_col, treatment_col, all_confounders, heterogeneity_cols=['Latent_Market_State'])
        st.session_state['main_engine'] = engine
    else:
        engine = st.session_state['main_engine']

    effects = engine.get_causal_effect(test_df[['Latent_Market_State']])
    avg_elasticity = np.mean(effects)
    naive_corr = test_df[[treatment_col, target_col]].corr().iloc[0,1]
    bias_delta = avg_elasticity - naive_corr

    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        t("âš¡ Insights & Elasticity", "âš¡ æ´å¯Ÿèˆ‡å½ˆæ€§åˆ†æ"),
        t("ğŸ”® Sensitivity Simulator", "ğŸ”® æ•æ„Ÿåº¦æ¨¡æ“¬å™¨"),
        t("âš”ï¸ Model Battle", "âš”ï¸ æ¨¡å‹ç«¶æŠ€å ´"),
        t("âš–ï¸ Evaluation", "âš–ï¸ æ¨¡å‹è©•ä¼°"),
        t("ğŸŒŒ Parallel Universe", "ğŸŒŒ å¹³è¡Œæ™‚ç©ºæ¨¡æ“¬"),
        t("ğŸ“‹ Executive Report", "ğŸ“‹ åŸ·è¡Œå ±å‘Š")
    ])
    
    with tab1:
        st.subheader(t("Separating Signal from Noise", "æ’¥é–‹é›²éœ§è¦‹é’å¤©ï¼šå€åˆ†ä¿¡è™Ÿèˆ‡é›œè¨Š"))
        c_dag, c_explain = st.columns([1, 2])
        with c_dag:
            dot = graphviz.Digraph()
            dot.attr(rankdir='LR', size='8,5')
            dot.attr('node', shape='box', style='filled,rounded', fontname='Inter')
            dot.node('T', t('Treatment', 'å¹²é æ±ºç­–'), fillcolor='#d1fae5', color='#059669')
            dot.node('Y', t('Outcome', 'æœ€çµ‚çµæœ'), fillcolor='#dbeafe', color='#2563eb')
            dot.node('W', t('Confounders', 'æ··é›œå› å­'), shape='ellipse', fillcolor='#fee2e2', color='#dc2626')
            dot.edge('T', 'Y', label=t(' Causal Link', ' å› æœéˆçµ'), color='#059669', penwidth='2.0')
            dot.edge('W', 'T', style='dashed', color='#94a3b8')
            dot.edge('W', 'Y', style='dashed', color='#94a3b8')
            st.graphviz_chart(dot)
        with c_explain:
            st.markdown(f"""<div class='theory-box'><b>{t("The 'Noise Cancellation' Logic:", "ã€Œé›œè¨Šæ¶ˆé™¤ã€é‚è¼¯ï¼š")}</b><br>
            {t("Standard correlations are biased because <b>Confounders</b> (Red) affect both your decision (T) and the outcome (Y).", "æ¨™æº–ç›¸é—œæ€§åˆ†æå­˜åœ¨åèª¤ï¼Œå› ç‚º <b>æ··é›œå› å­</b> (ç´…è‰²) åŒæ™‚å½±éŸ¿ä½ çš„æ±ºç­– (T) èˆ‡çµæœ (Y)ã€‚")}<br><br>
            {t("We use <b>Double Machine Learning</b> to 'block' the red dashed lines, isolating the pure green causal link.", "æˆ‘å€‘ä½¿ç”¨ <b>é›™é‡æ©Ÿå™¨å­¸ç¿’ (DML)</b> ä¾†ã€Œé˜»æ–·ã€ç´…è‰²è™›ç·šï¼Œå¾è€Œåˆ†é›¢å‡ºç´”ç²¹çš„ç¶ è‰²å› æœéˆçµã€‚")}</div>""", unsafe_allow_html=True)

        k1, k2, k3 = st.columns(3)
        k1.metric(t("True Causal Elasticity", "çœŸå¯¦å› æœå½ˆæ€§"), f"{avg_elasticity:.3f}", help=t("The actual impact of Treatment on Target, free of bias.", "å¹²é å°ç›®æ¨™çš„å¯¦éš›å½±éŸ¿ï¼Œå·²æ’é™¤åèª¤ã€‚"))
        k2.metric(t("Naive Correlation", "åŸå§‹ç›¸é—œæ€§"), f"{naive_corr:.3f}", delta=f"{t('Bias Detected', 'åµæ¸¬åˆ°åèª¤')}: {bias_delta:.3f}", delta_color="inverse")
        bias_status = t("Significant Bias", "é¡¯è‘—åèª¤") if abs(bias_delta) > 0.1 else t("Clean Data", "æ•¸æ“šç´”æ·¨")
        k3.metric(t("Data Reliability", "æ•¸æ“šå¯é æ€§"), bias_status, delta=t("Corrected via DML", "å·²é€é DML ä¿®æ­£"))

        viz_df = pd.DataFrame({'Market Momentum': test_df['Latent_Market_State'], 'Impact': effects})
        fig_hte = px.scatter(viz_df, x='Market Momentum', y='Impact', color='Impact', color_continuous_scale='Tealgrn', title=t("Heterogeneous Treatment Effects", "ç•°è³ªæ€§å¹²é æ•ˆæœåˆ†æ"))
        fig_hte.update_layout(template="plotly_white", xaxis_title=t("Market Momentum (PCA)", "å¸‚å ´å‹•èƒ½ (PCA)"), yaxis_title=t("Causal Impact", "å› æœå½±éŸ¿"))
        st.plotly_chart(fig_hte, use_container_width=True)

    with tab2:
        st.subheader(t("ğŸ”® Multi-Scenario Simulator", "ğŸ”® å¤šæƒ…å¢ƒæ¨¡æ“¬å™¨"))
        col_in, col_out = st.columns([1, 2])
        with col_in:
            st.markdown(t("### ğŸ› ï¸ Adjust Strategy", "### ğŸ› ï¸ èª¿æ•´ç­–ç•¥"))
            curr_avg = float(test_df[treatment_col].mean())
            price_main = st.slider(t("Proposed Treatment Value (Center)", "å»ºè­°å¹²é å€¼ (ä¸­å¿ƒ)"), min_value=float(test_df[treatment_col].min()), max_value=float(test_df[treatment_col].max()), value=curr_avg)
            comp_mode = st.radio(t("Comparison Mode", "æ¯”è¼ƒæ¨¡å¼"), [t("Percentage (+/- %)", "ç™¾åˆ†æ¯” (+/- %)"), t("Manual Prices ($)", "æ‰‹å‹•è¼¸å…¥æ•¸å€¼ ($)")], horizontal=True)
            if "Percentage" in comp_mode or "ç™¾åˆ†æ¯”" in comp_mode:
                sensitivity = st.slider(t("Comparison Interval (+/- %)", "æ¯”è¼ƒå€é–“ (+/- %)"), 1, 20, 5)
                price_low, price_high = price_main * (1 - sensitivity/100), price_main * (1 + sensitivity/100)
                scenario_labels = [t(f"Lower (-{sensitivity}%)", f"è¼ƒä½ (-{sensitivity}%)"), t("Proposed", "å»ºè­°æ–¹æ¡ˆ"), t(f"Higher (+{sensitivity}%)", f"è¼ƒé«˜ (+{sensitivity}%)")]
            else:
                c1, c2 = st.columns(2)
                price_low = c1.number_input(t("Lower Scenario", "è¼ƒä½æƒ…å¢ƒ"), value=float(price_main*0.95))
                price_high = c2.number_input(t("Higher Scenario", "è¼ƒé«˜æƒ…å¢ƒ"), value=float(price_main*1.05))
                scenario_labels = [t("Scenario A (Low)", "æƒ…å¢ƒ A (ä½)"), t("Proposed", "å»ºè­°æ–¹æ¡ˆ"), t("Scenario B (High)", "æƒ…å¢ƒ B (é«˜)")]
            st.markdown(t("### ğŸ“¦ Inventory Specs", "### ğŸ“¦ åº«å­˜è¦æ ¼"))
            lead_time = st.number_input(t("Lead Time (Days)", "å‰ç½®æ™‚é–“ (å¤©)"), value=5)

        with col_out:
            sim_df_main = test_df.copy(); sim_df_main[f'New_{treatment_col}'] = price_main
            cf_main = engine.predict_counterfactual(sim_df_main, f'New_{treatment_col}')
            
            total_act = test_df[target_col].sum()
            total_sim = cf_main.sum()
            rev_sim = total_sim * price_main

            s1, s2, s3 = st.columns(3)
            s1.metric(t("Projected Demand", "é æ¸¬éœ€æ±‚é‡"), f"{total_sim:,.0f}", delta=f"{(total_sim-total_act):,.0f}")
            s2.metric(t("Projected Value", "é æ¸¬ç‡Ÿæ”¶"), f"${rev_sim:,.0f}", delta=f"${(rev_sim - (total_act*curr_avg)):,.0f}")
            st.info(t("Detailed scenario breakdown shown in report tab.", "è©³ç´°æƒ…å¢ƒåˆ†æé¡¯ç¤ºæ–¼å ±å‘Šåˆ†é ä¸­ã€‚"))

            fig_cf = go.Figure()
            fig_cf.add_trace(go.Scatter(y=test_df[target_col], name=t("Historical Actuals", "æ­·å²å¯¦éš›å€¼"), line=dict(color='#cbd5e1')))
            fig_cf.add_trace(go.Scatter(y=cf_main, name=t("Causal Prediction", "å› æœé æ¸¬"), line=dict(color='#0ea5e9', width=4)))
            fig_cf.update_layout(title=t("Strategic Impact Visualization", "ç­–ç•¥å½±éŸ¿è¦–è¦ºåŒ–"), template="plotly_white")
            st.plotly_chart(fig_cf, use_container_width=True)

    with tab3:
        st.subheader(t("âš”ï¸ Battle of the Meta-Learners", "âš”ï¸ å…ƒå­¸ç¿’å™¨ç«¶æŠ€å ´"))
        if st.session_state.get('cate_results') is None:
             if st.button(t("ğŸ Start Tournament", "ğŸ é–‹å§‹ç«¶è³½"), use_container_width=True):
                 meta_feats = all_confounders + ['Latent_Market_State']
                 with st.spinner(t("Running Causal Tournament...", "å› æœæ¨¡å‹ç«¶è³½é€²è¡Œä¸­...")):
                    st.session_state['cate_results'] = train_meta_learners(df_eng, target_col, treatment_col, meta_feats)
        
        if st.session_state.get('cate_results') is not None:
            cate_results = st.session_state['cate_results']
            fig_hist = px.histogram(cate_results, barmode='overlay', title=t("Distribution of Causal Estimates", "å› æœä¼°è¨ˆå€¼åˆ†å¸ƒ"))
            st.plotly_chart(fig_hist, use_container_width=True)
            st.success(t("Analysis complete. X-Learner is typically the most robust for unbalanced data.", "åˆ†æå®Œæˆã€‚å°æ–¼ä¸å¹³è¡¡æ•¸æ“šï¼ŒX-Learner é€šå¸¸æœ€ç‚ºç©©å¥ã€‚"))

    with tab4:
        st.subheader(t("âš–ï¸ Methodology Evaluation", "âš–ï¸ ç®—æ³•è©•ä¼°"))
        st.markdown(f"""<div class='theory-box'><b>{t("Why DML? (3-Fold Cross-Fitting)", "ç‚ºä»€éº¼é¸æ“‡ DMLï¼Ÿ(ä¸‰æŠ˜äº¤å‰é©—è­‰)")}</b><br>
        {t("Standard models confuse correlation with causation. To fix this, we use the <b>Frisch-Waugh-Lovell (FWL)</b> theorem.", "æ¨™æº–æ¨¡å‹å¸¸æ··æ·†ç›¸é—œæ€§èˆ‡å› æœé—œä¿‚ã€‚ç‚ºäº†ä¿®æ­£é€™é»ï¼Œæˆ‘å€‘æ¡ç”¨ <b>FWL å®šç†</b>ã€‚")}</div>""", unsafe_allow_html=True)
        if st.session_state.get('fold_metrics') is None:
            kf = KFold(n_splits=3, shuffle=True, random_state=42)
            fold_metrics, ols_fold_metrics = [], []
            with st.spinner(t("Running 3-Fold Stability Check...", "æ­£åœ¨åŸ·è¡Œä¸‰æŠ˜ç©©å®šæ€§æª¢æŸ¥...")):
                for train_idx, val_idx in kf.split(train_df):
                    X_tr, X_val = train_df.iloc[train_idx], train_df.iloc[val_idx]
                    f_engine = RealCausalEngine()
                    f_engine.train(X_tr, target_col, treatment_col, all_confounders, heterogeneity_cols=['Latent_Market_State'])
                    fold_metrics.append(np.mean(f_engine.get_causal_effect(X_val[['Latent_Market_State']])))
                    ols = LinearRegression().fit(X_tr[[treatment_col] + all_confounders], X_tr[target_col])
                    ols_fold_metrics.append(ols.coef_[0])
            st.session_state['fold_metrics'] = fold_metrics
            st.session_state['ols_fold_metrics'] = ols_fold_metrics
        
        fig_val = go.Figure()
        fig_val.add_trace(go.Bar(x=['Fold 1', 'Fold 2', 'Fold 3'], y=st.session_state['fold_metrics'], name='DML (Causal)', marker_color='#0ea5e9'))
        fig_val.add_trace(go.Bar(x=['Fold 1', 'Fold 2', 'Fold 3'], y=st.session_state['ols_fold_metrics'], name='OLS (Traditional)', marker_color='#ef4444'))
        st.plotly_chart(fig_val, use_container_width=True)

    with tab5:
        st.subheader(t("ğŸŒŒ Parallel Universe Simulation", "ğŸŒŒ å¹³è¡Œæ™‚ç©ºæ¨¡æ“¬"))
        col_p1, col_p2 = st.columns([1, 3])
        with col_p1:
            st.markdown(t("### âš™ï¸ Universe B Settings", "### âš™ï¸ å¹³è¡Œæ™‚ç©º B é…ç½®"))
            price_b = st.slider(t("Universe B Price ($)", "æ™‚ç©º B æ•¸å€¼ ($)"), min_value=float(test_df[treatment_col].min()), max_value=float(test_df[treatment_col].max()), value=float(test_df[treatment_col].mean()))
            target_sl = st.slider(t("Target Service Level (%)", "ç›®æ¨™æœå‹™æ°´æº– (%)"), 90, 99, 95) / 100
            sim_lt = st.number_input(t("Supply Lead Time (Days)", "ä¾›æ‡‰å‰ç½®æ™‚é–“ (å¤©)"), value=5, key="plt")
        
        with col_p2:
            # Calculation logic for Universe A vs B
            z_score = norm.ppf(target_sl)
            demand_a = test_df[target_col]
            ss_a = z_score * demand_a.std() * np.sqrt(sim_lt)
            ts_a = np.full(len(demand_a), (demand_a.mean() * sim_lt) + ss_a)
            
            sim_df_b = test_df.copy(); sim_df_b[f'New_{treatment_col}'] = price_b
            demand_b = engine.predict_counterfactual(sim_df_b, f'New_{treatment_col}')
            preds_b = engine.base_model.predict(test_df[engine.features])
            ss_b = z_score * (test_df[target_col] - preds_b).std() * np.sqrt(sim_lt)
            ts_b = (demand_b * sim_lt) + ss_b

            inv_a, short_a, lost_a = simulate_inventory_dynamic(demand_a, ts_a, sim_lt)
            inv_b, short_b, lost_b = simulate_inventory_dynamic(demand_b, ts_b, sim_lt)
            
            rev_a = ((demand_a - lost_a) * float(test_df[treatment_col].mean())).sum()
            rev_b = ((demand_b - lost_b) * price_b).sum()

            st.session_state['sim_results'] = {'rev_a': rev_a, 'rev_b': rev_b, 'inv_a': inv_a.mean(), 'inv_b': inv_b.mean(), 'short_a': short_a, 'short_b': short_b}

            c1, c2, c3 = st.columns(3)
            c1.metric(t("Revenue B vs A", "ç‡Ÿæ”¶ï¼šæ™‚ç©º B vs A"), f"${rev_b:,.0f}", delta=f"${(rev_b-rev_a):,.0f}")
            c2.metric(t("Avg Inventory B", "æ™‚ç©º B å¹³å‡åº«å­˜"), f"{inv_b.mean():,.0f}", delta=f"{(inv_b.mean()-inv_a.mean()):,.0f}", delta_color="inverse")
            c3.metric(t("Shortage Events B", "æ™‚ç©º B ç¼ºè²¨æ¬¡æ•¸"), f"{short_b} days", delta=f"{short_b-short_a}", delta_color="inverse")

            fig_p = go.Figure()
            fig_p.add_trace(go.Scatter(y=inv_a, name=t("Universe A (Static)", "æ™‚ç©º A (éœæ…‹)"), line=dict(color='#94a3b8')))
            fig_p.add_trace(go.Scatter(y=inv_b, name=t("Universe B (Dynamic)", "æ™‚ç©º B (å‹•æ…‹)"), line=dict(color='#0ea5e9')))
            st.plotly_chart(fig_p, use_container_width=True)

    with tab6:
        st.subheader(t("ğŸ“‹ Executive Summary", "ğŸ“‹ æ±ºç­–åŸ·è¡Œæ‘˜è¦"))
        sim = st.session_state.get('sim_results', {})
        
        report_txt = f"""
        {t("CAUSAL AI EXECUTIVE SUMMARY", "å› æœ AI åŸ·è¡Œæ‘˜è¦")}
        ===========================
        
        1. {t("EXECUTIVE FINDINGS", "æ ¸å¿ƒåˆ†æç™¼ç¾")}
        ---------------------
        - {t("True Causal Elasticity", "çœŸå¯¦å› æœå½ˆæ€§")}: {avg_elasticity:.4f}
        - {t("Naive Correlation", "åŸå§‹ç›¸é—œæ€§")}: {naive_corr:.4f}
        - {t("Bias Detected", "åµæ¸¬åèª¤")}: {bias_delta:.4f}
        
        2. {t("PARALLEL UNIVERSE RESULTS", "å¹³è¡Œæ™‚ç©ºæ¨¡æ“¬çµæœ")}
        -----------------------------------------
        - {t("Revenue", "ç‡Ÿç‡Ÿæ”¶")}: ${sim.get('rev_a',0):,.0f} (A) vs ${sim.get('rev_b',0):,.0f} (B)
        - {t("Shortages", "ç¼ºè²¨å¤©æ•¸")}: {sim.get('short_a',0)} (A) vs {sim.get('short_b',0)} (B)
        
        3. {t("STRATEGIC RECOMMENDATION", "æˆ°ç•¥å»ºè­°")}
        ---------------------------
        {t("Focus on 'High Momentum' periods to adjust strategy.", "å°ˆæ³¨æ–¼ã€Œé«˜å‹•èƒ½ã€æ™‚æœŸä¾†èª¿æ•´ç­–ç•¥ã€‚")}
        """
        st.text_area(t("Report Preview", "å ±å‘Šé è¦½"), report_txt, height=300)
        if st.button(t("ğŸ“„ Download PDF Report", "ğŸ“„ ä¸‹è¼‰ PDF å ±å‘Š")):
            pdf = FPDF(); pdf.add_page(); pdf.set_font("Arial", size=12)
            pdf.multi_cell(0, 10, report_txt.encode('latin-1', 'replace').decode('latin-1'))
            st.download_button("Download PDF", pdf.output(dest='S'), "report.pdf")